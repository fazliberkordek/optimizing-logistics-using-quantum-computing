{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "eadcc260-1c12-4ac3-a623-330241074f74",
      "metadata": {
        "id": "eadcc260-1c12-4ac3-a623-330241074f74"
      },
      "source": [
        "# [Filtering VQE](https://arxiv.org/abs/2106.10055) - a Quantum Heuristic for solving VRP"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9a697cb-2958-44c4-9337-887435a334c7",
      "metadata": {
        "id": "c9a697cb-2958-44c4-9337-887435a334c7"
      },
      "source": [
        "***\n",
        "### Authors: **Walid El Maouaki** and **Atharva Vidwans**\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e745489-1aee-4c32-86e7-3e192be0e1dd",
      "metadata": {
        "id": "4e745489-1aee-4c32-86e7-3e192be0e1dd"
      },
      "source": [
        "### **Theory**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be5e74c5-9152-48fd-a1a0-a188b1e7306d",
      "metadata": {
        "id": "be5e74c5-9152-48fd-a1a0-a188b1e7306d"
      },
      "source": [
        "The aim of this notebook is to implement the Filtering VQE algorithm for solving the VRP. We will not here explain all the algorithm, so just refer to [the original article](https://arxiv.org/abs/2106.10055) to understand it properly. Essentially, a regular VQE would use the expectation value of a hamiltonian $H$ on a quantum parametriced circuit in order to try and minimize that expectation value. What the Filtering VQE will do is use that parametriced circuit in order to approximate the action of some operator $F_\\tau = f(H, \\tau)$ that effectively projects a given wavefunction into lower energy eigenstates, thus, filtering the higher energy eigenstates."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f25dd27-5d3f-4c99-a0f5-675e2d818e72",
      "metadata": {
        "id": "2f25dd27-5d3f-4c99-a0f5-675e2d818e72"
      },
      "source": [
        "Here, we will not cover how the VRP is formulated and solved in detail, since that is already exposed on [the Qiskit tutorial on the VRP](https://qiskit.org/documentation/tutorials/optimization/7_examples_vehicle_routing.html). However, we add an little summary of the used notation\n",
        "\n",
        "\n",
        "---\n",
        "Mathematically speaking, the vehicle routing problem (VRP) is a combinatorial problem, wherein the best routes from a depot to a number of clients and back to the depot are sought, given a number of available vehicles. There are a number of formulations possible, extending a number of formulations of the traveling salesman problem [Applegate et al, 2006]. Here, we present a formulation known as MTZ [Miller, Tucker, Zemlin, 1960]. \n",
        "\n",
        "Let $n$ be the number of clients (indexed as $1,\\dots,n$), and $K$ be the number of available vehicles. Let $x_{ij} = \\{0,1\\}$ be the binary decision variable which, if it is $1$, activates the segment from node $i$ to node $j$. The node index runs from $0$ to $n$, where $0$ is (by convention) the depot. There are twice as many distinct decision variables as edges. For example, in a fully connected graph, there are $n(n+1)$ binary decision variables. \n",
        "\n",
        "If two nodes $i$ and $j$ have a link from $i$ to $j$, we write $i \\sim j$. We also denote with $\\delta(i)^+$ the set of nodes to which $i$ has a link, i.e., $j \\in \\delta(i)^+$ if and only if $i \\sim j$. Similarly, we denote with \n",
        "$\\delta(i)^-$ the set of nodes which are connected to $i$, in the sense that $j \\in \\delta(i)^-$ if and only if $j \\sim i$. \n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Thus, there will be a variable $x_{ij}$ that will tell if there is a vehicle going from node $i$ to node $j$. Our way to obtain a solution is to consider a vector ${\\bf z}$ containing all that information\n",
        "\n",
        "$$\n",
        "{\\bf z} = [x_{01},x_{02},\\ldots,x_{10}, x_{12},\\ldots,x_{n(n-1)}]^T,\n",
        "$$\n",
        "\n",
        "and, as $x_{ij}$ is a binary variable, that vector can be identified as a bitstring. This is why it makes sense to try and map the problem into a QUBO and then into an Ising Hamiltonian (it's diagonal); our solution can be depicted as one of the eigenstates that will, in fact, be one of the computational basis states.\n",
        "\n",
        "In a very simple exercise, imagine that we are given the solution\n",
        "$$\n",
        "{\\bf z} = [x_{01},x_{10}]^T = [1,1]^T,\n",
        "$$\n",
        "Thus, $x_{01}=1$ means that there is a vehicle going from the depot to node $1$ and $x_{10}=1$ means that there is a vehicle going from node $1$ to the depot. There are no more variables and that means that there is only $K=1$ vehicle visiting a single depot. Quite a trivial example."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1cd4ef4-17db-4502-914d-c5181df99dbb",
      "metadata": {
        "id": "d1cd4ef4-17db-4502-914d-c5181df99dbb"
      },
      "source": [
        "#### **Importing standard Qiskit libraries and other necessary modules**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ed85b5f6-b755-411c-876b-bab2e9370506",
      "metadata": {
        "id": "ed85b5f6-b755-411c-876b-bab2e9370506",
        "outputId": "bbbf6b7c-9241-4a23-b311-e97d8f4822db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cplex\n",
            "  Downloading cplex-22.1.0.0-cp37-cp37m-manylinux1_x86_64.whl (43.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 43.3 MB 17 kB/s \n",
            "\u001b[?25hInstalling collected packages: cplex\n",
            "Successfully installed cplex-22.1.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting qiskit\n",
            "  Downloading qiskit-0.37.1.tar.gz (13 kB)\n",
            "Collecting qiskit-terra==0.21.1\n",
            "  Downloading qiskit_terra-0.21.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7 MB 7.0 MB/s \n",
            "\u001b[?25hCollecting qiskit-aer==0.10.4\n",
            "  Downloading qiskit_aer-0.10.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (18.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 18.0 MB 364 kB/s \n",
            "\u001b[?25hCollecting qiskit-ibmq-provider==0.19.2\n",
            "  Downloading qiskit_ibmq_provider-0.19.2-py3-none-any.whl (240 kB)\n",
            "\u001b[K     |████████████████████████████████| 240 kB 52.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.7/dist-packages (from qiskit-aer==0.10.4->qiskit) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-aer==0.10.4->qiskit) (1.7.3)\n",
            "Collecting websocket-client>=1.0.1\n",
            "  Downloading websocket_client-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider==0.19.2->qiskit) (2.8.2)\n",
            "Collecting websockets>=10.0\n",
            "  Downloading websockets-10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 35.6 MB/s \n",
            "\u001b[?25hCollecting requests-ntlm>=1.1.0\n",
            "  Downloading requests_ntlm-1.1.0-py2.py3-none-any.whl (5.7 kB)\n",
            "Requirement already satisfied: requests>=2.19 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider==0.19.2->qiskit) (2.23.0)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider==0.19.2->qiskit) (1.24.3)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.21.1->qiskit) (0.3.5.1)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.21.1->qiskit) (5.4.8)\n",
            "Collecting shared-memory38\n",
            "  Downloading shared_memory38-0.1.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (25 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.21.1->qiskit) (4.1.1)\n",
            "Collecting tweedledum<2.0,>=1.1\n",
            "  Downloading tweedledum-1.1.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (943 kB)\n",
            "\u001b[K     |████████████████████████████████| 943 kB 45.5 MB/s \n",
            "\u001b[?25hCollecting ply>=3.10\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting retworkx>=0.11.0\n",
            "  Downloading retworkx-0.11.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 58.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.21.1->qiskit) (1.7.1)\n",
            "Collecting stevedore>=3.0.0\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 7.2 MB/s \n",
            "\u001b[?25hCollecting symengine>=0.9\n",
            "  Downloading symengine-0.9.2-cp37-cp37m-manylinux2010_x86_64.whl (37.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 37.5 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.8.0->qiskit-ibmq-provider==0.19.2->qiskit) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.19.2->qiskit) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.19.2->qiskit) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.19.2->qiskit) (2022.6.15)\n",
            "Collecting ntlm-auth>=1.0.2\n",
            "  Downloading ntlm_auth-1.5.0-py2.py3-none-any.whl (29 kB)\n",
            "Collecting cryptography>=1.3\n",
            "  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 49.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.19.2->qiskit) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.19.2->qiskit) (2.21)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.9.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 27.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from stevedore>=3.0.0->qiskit-terra==0.21.1->qiskit) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.7.0->stevedore>=3.0.0->qiskit-terra==0.21.1->qiskit) (3.8.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy>=1.3->qiskit-terra==0.21.1->qiskit) (1.2.1)\n",
            "Building wheels for collected packages: qiskit\n",
            "  Building wheel for qiskit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for qiskit: filename=qiskit-0.37.1-py3-none-any.whl size=12067 sha256=989374e879cc83767d42d8a1ef9fd1c7c2f7a88f752a1e7c33f8fc1fe13446e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/3c/a3/bf8c2931e17937329c34a88b76cb88cbb7f9f2692fa7cfbcd1\n",
            "Successfully built qiskit\n",
            "Installing collected packages: pbr, tweedledum, symengine, stevedore, shared-memory38, retworkx, ply, ntlm-auth, cryptography, websockets, websocket-client, requests-ntlm, qiskit-terra, qiskit-ibmq-provider, qiskit-aer, qiskit\n",
            "Successfully installed cryptography-37.0.4 ntlm-auth-1.5.0 pbr-5.9.0 ply-3.11 qiskit-0.37.1 qiskit-aer-0.10.4 qiskit-ibmq-provider-0.19.2 qiskit-terra-0.21.1 requests-ntlm-1.1.0 retworkx-0.11.0 shared-memory38-0.1.2 stevedore-3.5.0 symengine-0.9.2 tweedledum-1.1.1 websocket-client-1.3.3 websockets-10.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement qiskit.aqua.operators.expectations (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for qiskit.aqua.operators.expectations\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement qiskit_expectation (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for qiskit_expectation\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting qiskit_optimization\n",
            "  Downloading qiskit_optimization-0.4.0-py3-none-any.whl (159 kB)\n",
            "\u001b[K     |████████████████████████████████| 159 kB 5.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: qiskit-terra>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from qiskit_optimization) (0.21.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from qiskit_optimization) (1.21.6)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from qiskit_optimization) (2.6.3)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.7/dist-packages (from qiskit_optimization) (1.7.3)\n",
            "Collecting docplex>=2.21.207\n",
            "  Downloading docplex-2.23.222.tar.gz (610 kB)\n",
            "\u001b[K     |████████████████████████████████| 610 kB 57.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=40.1.0 in /usr/local/lib/python3.7/dist-packages (from qiskit_optimization) (57.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from docplex>=2.21.207->qiskit_optimization) (1.15.0)\n",
            "Requirement already satisfied: ply>=3.10 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra>=0.20.0->qiskit_optimization) (3.11)\n",
            "Requirement already satisfied: symengine>=0.9 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra>=0.20.0->qiskit_optimization) (0.9.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from qiskit-terra>=0.20.0->qiskit_optimization) (4.1.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra>=0.20.0->qiskit_optimization) (0.3.5.1)\n",
            "Requirement already satisfied: shared-memory38 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra>=0.20.0->qiskit_optimization) (0.1.2)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra>=0.20.0->qiskit_optimization) (3.5.0)\n",
            "Requirement already satisfied: retworkx>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra>=0.20.0->qiskit_optimization) (0.11.0)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra>=0.20.0->qiskit_optimization) (5.4.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra>=0.20.0->qiskit_optimization) (2.8.2)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra>=0.20.0->qiskit_optimization) (1.7.1)\n",
            "Requirement already satisfied: tweedledum<2.0,>=1.1 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra>=0.20.0->qiskit_optimization) (1.1.1)\n",
            "Requirement already satisfied: importlib-metadata>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from stevedore>=3.0.0->qiskit-terra>=0.20.0->qiskit_optimization) (4.12.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from stevedore>=3.0.0->qiskit-terra>=0.20.0->qiskit_optimization) (5.9.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.7.0->stevedore>=3.0.0->qiskit-terra>=0.20.0->qiskit_optimization) (3.8.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy>=1.3->qiskit-terra>=0.20.0->qiskit_optimization) (1.2.1)\n",
            "Building wheels for collected packages: docplex\n",
            "  Building wheel for docplex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docplex: filename=docplex-2.23.222-py3-none-any.whl size=662847 sha256=62ce42c144a618e5d7e6c27918ddbb673add2ef46c92eb2cd18b1d1fd007f0a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c9/fb/cee5a89f304e77a39c466e625ac2830434b76eb8384999d116\n",
            "Successfully built docplex\n",
            "Installing collected packages: docplex, qiskit-optimization\n",
            "Successfully installed docplex-2.23.222 qiskit-optimization-0.4.0\n",
            "\u001b[31mERROR: Directory '.[dask]' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dask_jobqueue\n",
            "  Downloading dask_jobqueue-0.7.4-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 595 kB/s \n",
            "\u001b[?25hCollecting distributed>=2.23\n",
            "  Downloading distributed-2022.2.0-py3-none-any.whl (837 kB)\n",
            "\u001b[K     |████████████████████████████████| 837 kB 11.9 MB/s \n",
            "\u001b[?25hCollecting dask>=2.23\n",
            "  Downloading dask-2022.2.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 42.9 MB/s \n",
            "\u001b[?25hCollecting fsspec>=0.6.0\n",
            "  Downloading fsspec-2022.7.1-py3-none-any.whl (141 kB)\n",
            "\u001b[K     |████████████████████████████████| 141 kB 57.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from dask>=2.23->dask_jobqueue) (0.12.0)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from dask>=2.23->dask_jobqueue) (1.3.0)\n",
            "Collecting partd>=0.3.10\n",
            "  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from dask>=2.23->dask_jobqueue) (21.3)\n",
            "Collecting pyyaml>=5.3.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 49.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tornado>=5 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.23->dask_jobqueue) (5.1.1)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.23->dask_jobqueue) (1.7.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.23->dask_jobqueue) (1.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed>=2.23->dask_jobqueue) (57.4.0)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.23->dask_jobqueue) (5.4.8)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.23->dask_jobqueue) (7.1.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.23->dask_jobqueue) (2.11.3)\n",
            "Collecting cloudpickle>=1.1.1\n",
            "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.23->dask_jobqueue) (2.4.0)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.23->dask_jobqueue) (2.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->dask>=2.23->dask_jobqueue) (3.0.9)\n",
            "Collecting locket\n",
            "  Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.23->dask_jobqueue) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->distributed>=2.23->dask_jobqueue) (2.0.1)\n",
            "Installing collected packages: locket, pyyaml, partd, fsspec, cloudpickle, dask, distributed, dask-jobqueue\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2.12.0\n",
            "    Uninstalling dask-2.12.0:\n",
            "      Successfully uninstalled dask-2.12.0\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 1.25.3\n",
            "    Uninstalling distributed-1.25.3:\n",
            "      Successfully uninstalled distributed-1.25.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.1.0 which is incompatible.\u001b[0m\n",
            "Successfully installed cloudpickle-2.1.0 dask-2022.2.0 dask-jobqueue-0.7.4 distributed-2022.2.0 fsspec-2022.7.1 locket-1.0.0 partd-1.2.0 pyyaml-6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install cplex \n",
        "# This are items I need to install and I had to make some changes to imports to get them to work.\n",
        "!pip install qiskit \n",
        "!pip install qiskit.aqua.operators.expectations\n",
        "!pip install qiskit_expectation\n",
        "!pip install qiskit_optimization\n",
        "!pip install .[dask]\n",
        "!pip install dask_jobqueue\n",
        "\n",
        "from time import process_time\n",
        "import numpy as np\n",
        "\n",
        "# Visualization tool\n",
        "from qiskit.visualization import *\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.axes as axes\n",
        "\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import time\n",
        "import math\n",
        "\n",
        "from qiskit.algorithms.optimizers import ADAM, CG, GSLS, NELDER_MEAD, NFT, POWELL, SPSA, TNC, COBYLA, L_BFGS_B, SLSQP, AQGD, P_BFGS, GradientDescent\n",
        "from qiskit import QuantumCircuit, ClassicalRegister, QuantumRegister, Aer, transpile, execute\n",
        "from qiskit.utils  import QuantumInstance, algorithm_globals\n",
        "from qiskit.circuit import ParameterVector\n",
        "from qiskit.opflow import Z, I, X, Y, ListOp, PauliExpectation, CVaRExpectation, StateFn, CircuitSampler, CircuitStateFn, ListOp\n",
        "\n",
        "# New Imports\n",
        "from qiskit.providers.aer import AerSimulator\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from dask.distributed import LocalCluster, Client\n",
        "from dask_jobqueue import LSFCluster\n",
        "# End of new imports\n",
        "\n",
        "from qiskit.algorithms import VQE, QAOA\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from qiskit import *\n",
        "from qiskit_optimization import QuadraticProgram\n",
        "from qiskit_optimization.algorithms import MinimumEigenOptimizer\n",
        "# from qiskit.aqua.operators.expectations import CVaRExpectation, PauliExpectation - Does not seem to work,  but has been replaced\n",
        "\n",
        "import qiskit.tools.jupyter\n",
        "# %qiskit_version_table\n",
        "\n",
        "# Ignore Deprecation Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "c704e112"
      },
      "source": [
        "*** *italicized text*\n",
        "### **Allocating Optimal Amount of Resources for Job - Currently Commented Out** ###\n",
        "***"
      ],
      "id": "c704e112"
    },
    {
      "cell_type": "code",
      "source": [
        "# Code for limiting requirements for this program based on device (not implemented yet)\n",
        "# cluster = LSFCluster(cores=4, memory=\"4GB\") # 4 CPU cores, 4GB of memory\n",
        "# DASK_client = Client(cluster)\n",
        "# backend = AerSimulator # Linking to the Aer Simulator\n",
        "# backend.set_options(executor=my_dask_client, max_job_size=10) # Arbitrary number of jobs, but a large one just in case.\n",
        "\n",
        "# This code is only for if one wants to implement their programs on their own devices, not on IBM's devices.\n",
        "# To properly use this code, one has to remove the \"backend =\" code and replace it with just \"backend\""
      ],
      "metadata": {
        "id": "TX6MfCKlx8Ao"
      },
      "execution_count": 2,
      "outputs": [],
      "id": "TX6MfCKlx8Ao"
    },
    {
      "cell_type": "code",
      "source": [
        "# Code for dividing overall job into one circuit per job, to potentially lead to less errors and a faster runtime.\n",
        "backend = AerSimulator()\n",
        "# Setting an executor and a maximum job size (maximum number of circuits that can make up a job)\n",
        "excute = ThreadPoolExecutor(max_workers=2)\n",
        "backend.set_options(executor=excute)\n",
        "backend.set_options(max_job_size=1) \n",
        "# Setting one job per circuit, as this allows each circuit to be run. This would theoretically allow for maximum accuracy as each circuit would have the minimum number of gates\n",
        "# for the lowest possible error rate compared to running all circuits for one job (per layer), as in the current program.\n"
      ],
      "metadata": {
        "id": "czj8UKpnekcN"
      },
      "id": "czj8UKpnekcN",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "5f27b82b-6674-49de-ad0e-ef91e4a98abe",
      "metadata": {
        "tags": [],
        "id": "5f27b82b-6674-49de-ad0e-ef91e4a98abe"
      },
      "source": [
        "## We have defined 3 classes:\n",
        "**Class Initializer** \n",
        "- *GenerateInstance* : This method initializes the variables i.e. the number of nodes(including the depot)-n  and number of vehicles-K  \n",
        "\n",
        "**Class ClassicalOptimizer**\n",
        "- For a classical solution, we use IBM ILOG CPLEX. CPLEX is able to find the exact solution of this problem. We first define a ClassicalOptimizer class that encodes the problem in a way that CPLEX can solve, and then instantiate the class and solve it\n",
        "\n",
        "**Class QuantumOptimizer**\n",
        "- *binary_representation* : encodes the problem (M) into a QP terms (that’s basically linear algebra); \n",
        "- *construct_problem* : constructs a QUBO optimization problem as an instance of QuadraticProgram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "14137913-5458-4227-acc2-742e8a883297",
      "metadata": {
        "id": "14137913-5458-4227-acc2-742e8a883297"
      },
      "outputs": [],
      "source": [
        "# Classes for solving the VRP problem\n",
        "\n",
        "class Initializer():\n",
        "\n",
        "    def __init__(self, n, b):\n",
        "        self.n = n\n",
        "        self.b = b\n",
        "\n",
        "    def generate_instance(self):\n",
        "\n",
        "        n = self.n\n",
        "        b = self.b\n",
        "        \n",
        "        # np.random.seed(33)\n",
        "        np.random.seed(100*n + b)\n",
        "\n",
        "        xc = (np.random.rand(n) - 0.5) * 50\n",
        "        yc = (np.random.rand(n) - 0.5) * 50\n",
        "\n",
        "        instance = np.zeros([n, n])\n",
        "        for ii in range(0, n):\n",
        "            for jj in range(ii + 1, n):\n",
        "                instance[ii, jj] = (xc[ii] - xc[jj]) ** 2 + (yc[ii] - yc[jj]) ** 2\n",
        "                instance[jj, ii] = instance[ii, jj]\n",
        "\n",
        "        return xc, yc, instance\n",
        "    \n",
        "    \n",
        "try:\n",
        "    import cplex\n",
        "    from cplex.exceptions import CplexError\n",
        "except: \n",
        "    print(\"Warning: Cplex not found.\")\n",
        "\n",
        "class ClassicalOptimizer:\n",
        "\n",
        "    def __init__(self, instance,n,K):\n",
        "\n",
        "        self.instance = instance\n",
        "        self.n = n  # number of nodes\n",
        "        self.K = K  # number of vehicles\n",
        "\n",
        "\n",
        "    def compute_allowed_combinations(self):\n",
        "        f = math.factorial\n",
        "        return f(self.n) / f(self.K) / f(self.n-self.K)\n",
        "\n",
        "\n",
        "    def cplex_solution(self):\n",
        "\n",
        "        # refactoring\n",
        "        instance = self.instance\n",
        "        n = self.n\n",
        "        K = self.K\n",
        "\n",
        "        my_obj = list(instance.reshape(1, n**2)[0])+[0. for x in range(0,n-1)]\n",
        "        my_ub = [1 for x in range(0,n**2+n-1)]\n",
        "        my_lb = [0 for x in range(0,n**2)] + [0.1 for x in range(0,n-1)]\n",
        "        my_ctype = \"\".join(['I' for x in range(0,n**2)]) + \"\".join(['C' for x in range(0,n-1)])\n",
        "\n",
        "        my_rhs = 2*([K] + [1 for x in range(0,n-1)]) + [1-0.1 for x in range(0,(n-1)**2-(n-1))] + [0 for x in range(0,n)]\n",
        "        my_sense = \"\".join(['E' for x in range(0,2*n)]) + \"\".join(['L' for x in range(0,(n-1)**2-(n-1))])+\"\".join(['E' for x in range(0,n)])\n",
        "\n",
        "        try:\n",
        "            my_prob = cplex.Cplex()\n",
        "            self.populatebyrow(my_prob,my_obj,my_ub,my_lb,my_ctype,my_sense,my_rhs)\n",
        "\n",
        "            my_prob.solve()\n",
        "\n",
        "        except CplexError as exc:\n",
        "            print(exc)\n",
        "            return\n",
        "\n",
        "        x = my_prob.solution.get_values()\n",
        "        x = np.array(x)\n",
        "        cost = my_prob.solution.get_objective_value()\n",
        "\n",
        "        return x,cost\n",
        "    \n",
        "\n",
        "    def populatebyrow(self,prob,my_obj,my_ub,my_lb,my_ctype,my_sense,my_rhs):\n",
        "\n",
        "        n = self.n\n",
        "    \n",
        "        prob.objective.set_sense(prob.objective.sense.minimize)\n",
        "        prob.variables.add(obj = my_obj, lb = my_lb, ub = my_ub, types = my_ctype)\n",
        "    \n",
        "        prob.set_log_stream(None)\n",
        "        prob.set_error_stream(None)\n",
        "        prob.set_warning_stream(None)\n",
        "        prob.set_results_stream(None)\n",
        "\n",
        "        rows = []\n",
        "        for ii in range(0,n):\n",
        "            col = [x for x in range(0+n*ii,n+n*ii)]\n",
        "            coef = [1 for x in range(0,n)]\n",
        "            rows.append([col, coef])\n",
        "\n",
        "        for ii in range(0,n):\n",
        "            col = [x for x in range(0+ii,n**2,n)]\n",
        "            coef = [1 for x in range(0,n)]\n",
        "\n",
        "            rows.append([col, coef])\n",
        "\n",
        "        # Sub-tour elimination constraints:\n",
        "        for ii in range(0, n):\n",
        "            for jj in range(0,n):\n",
        "                if (ii != jj)and(ii*jj>0):\n",
        "\n",
        "                    col = [ii+(jj*n), n**2+ii-1, n**2+jj-1]\n",
        "                    coef = [1, 1, -1]\n",
        "\n",
        "                    rows.append([col, coef])\n",
        "\n",
        "        for ii in range(0,n):\n",
        "            col = [(ii)*(n+1)]\n",
        "            coef = [1]\n",
        "            rows.append([col, coef])\n",
        "\n",
        "        prob.linear_constraints.add(lin_expr=rows, senses=my_sense, rhs=my_rhs)\n",
        "\n",
        "        \n",
        "\n",
        "class QuantumOptimizer:\n",
        "\n",
        "    def __init__(self, instance, n, K):\n",
        "\n",
        "        self.instance = instance\n",
        "        self.n = n\n",
        "        self.K = K\n",
        "\n",
        "    def binary_representation(self,x_sol=0):\n",
        "\n",
        "        instance = self.instance\n",
        "        n = self.n\n",
        "        K = self.K\n",
        "\n",
        "        A = np.max(instance) * 100  # A parameter of cost function\n",
        "\n",
        "        # Determine the weights w\n",
        "        instance_vec = instance.reshape(n ** 2)\n",
        "        w_list = [instance_vec[x] for x in range(n ** 2) if instance_vec[x] > 0]\n",
        "        w = np.zeros(n * (n - 1))\n",
        "        for ii in range(len(w_list)):\n",
        "            w[ii] = w_list[ii]\n",
        "\n",
        "        # Some variables I will use\n",
        "        Id_n = np.eye(n)\n",
        "        Im_n_1 = np.ones([n - 1, n - 1])\n",
        "        Iv_n_1 = np.ones(n)\n",
        "        Iv_n_1[0] = 0\n",
        "        Iv_n = np.ones(n-1)\n",
        "        neg_Iv_n_1 = np.ones(n) - Iv_n_1\n",
        "\n",
        "        v = np.zeros([n, n*(n-1)])\n",
        "        for ii in range(n):\n",
        "            count = ii-1\n",
        "            for jj in range(n*(n-1)):\n",
        "\n",
        "                if jj//(n-1) == ii:\n",
        "                    count = ii\n",
        "\n",
        "                if jj//(n-1) != ii and jj%(n-1) == count:\n",
        "                    v[ii][jj] = 1.\n",
        "\n",
        "        vn = np.sum(v[1:], axis=0)\n",
        "\n",
        "        # Q defines the interactions between variables\n",
        "        Q = A*(np.kron(Id_n, Im_n_1) + np.dot(v.T, v))\n",
        "\n",
        "        # g defines the contribution from the individual variables\n",
        "        g = w - 2 * A * (np.kron(Iv_n_1,Iv_n) + vn.T) - \\\n",
        "                2 * A * K * (np.kron(neg_Iv_n_1, Iv_n) + v[0].T)\n",
        "\n",
        "        # c is the constant offset\n",
        "        c = 2 * A * (n-1) + 2 * A * (K ** 2)\n",
        "\n",
        "        try:\n",
        "            max(x_sol)\n",
        "            # Evaluates the cost distance from a binary representation of a path\n",
        "            fun = lambda x: np.dot(np.around(x), np.dot(Q, np.around(x))) + np.dot(g, np.around(x)) + c\n",
        "            cost = fun(x_sol)\n",
        "        except:\n",
        "            cost = 0\n",
        "\n",
        "        return Q, g, c, cost\n",
        "\n",
        "    def construct_problem(self, Q, g, c) -> QuadraticProgram:\n",
        "        qp = QuadraticProgram()\n",
        "        for i in range(n * (n - 1)):\n",
        "            qp.binary_var(str(i))\n",
        "        qp.objective.quadratic = Q\n",
        "        qp.objective.linear = g\n",
        "        qp.objective.constant = c\n",
        "        return qp\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d623deaa-0eed-4e15-aa05-94ddbc945ce5",
      "metadata": {
        "id": "d623deaa-0eed-4e15-aa05-94ddbc945ce5"
      },
      "source": [
        "### Initialize the Classical Optimizer\n",
        "- The below call initializes the classical optimizer to calcualte the Classical Cost and Classical solution. \n",
        "- Further, we also construct the Hamiltonian for given n and K values. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "dfdf229c-3389-4602-a773-dda4b8359471",
      "metadata": {
        "id": "dfdf229c-3389-4602-a773-dda4b8359471"
      },
      "outputs": [],
      "source": [
        "### Problem definition\n",
        "n= 2 # number of nodes + depot (n+1)\n",
        "K= 1 # number of vehicles\n",
        "b= 0\n",
        "\n",
        "initializer = Initializer(n,b)\n",
        "xc, yc, instance = initializer.generate_instance()\n",
        "\n",
        "classical_optimizer = ClassicalOptimizer(instance,n,K)\n",
        "\n",
        "x = None\n",
        "z = None\n",
        "try:\n",
        "    x, classical_cost = classical_optimizer.cplex_solution()\n",
        "    # Put the solution in the z variable\n",
        "    z = [x[ii] for ii in range(n**2) if ii//n != ii%n]\n",
        "    # Print the solution\n",
        "except: \n",
        "    pass\n",
        "\n",
        "algorithm_globals.massive=True\n",
        "# Instantiate the quantum optimizer class with parameters: \n",
        "quantum_optimizer = QuantumOptimizer(instance, n, K)\n",
        "\n",
        "try:\n",
        "    if z is not None:\n",
        "        Q, g, c, binary_cost = quantum_optimizer.binary_representation(x_sol = z)\n",
        "    else:\n",
        "        Q, g, c, binary_cost = quantum_optimizer.binary_representation()\n",
        "except NameError as e:\n",
        "    pass\n",
        "\n",
        "qp = quantum_optimizer.construct_problem(Q, g, c)\n",
        "\n",
        "quantum_instance = QuantumInstance(BasicAer.get_backend('qasm_simulator'),\n",
        "                                           seed_simulator=algorithm_globals.random_seed,\n",
        "                                           seed_transpiler=algorithm_globals.random_seed)\n",
        "\n",
        "vqe = VQE(quantum_instance=quantum_instance)\n",
        "optimizer = MinimumEigenOptimizer(min_eigen_solver=vqe)\n",
        "H, offset = optimizer._convert(qp, optimizer._converters).to_ising()\n",
        "#print(H) ## Uncomment this line to view the Hamiltonian\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "faa6a250-392e-4af2-bf42-b900d0b51372",
      "metadata": {
        "id": "faa6a250-392e-4af2-bf42-b900d0b51372"
      },
      "outputs": [],
      "source": [
        "def Ansatz(par, N, p=1):\n",
        "    qc = QuantumCircuit(N)\n",
        "    # Initial layer\n",
        "    for i in range(N):\n",
        "        qc.ry(par[i], i)\n",
        "        \n",
        "    for layer in range(p):\n",
        "        par_counter = N+2*(N-1)*layer\n",
        "    # Repeteable layer. To do the layer VQE thing, define this unit as a separate function\n",
        "        for i in range(N//2):\n",
        "            j = 2*i\n",
        "            qc.cx(j, j+1)\n",
        "            qc.ry(par[j+par_counter], j)\n",
        "            qc.ry(par[j+1+par_counter], j+1)\n",
        "\n",
        "        for i in range(N//2):\n",
        "            j = 2*i\n",
        "            if j+2<N: \n",
        "                qc.cx(j+1, j+2)\n",
        "                qc.ry(par[N-N%2+j+1+par_counter], j+2)\n",
        "                qc.ry(par[N-N%2+j+par_counter], j+1)\n",
        "    return qc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd7fb04e-c457-4093-ba9e-da0b063b6427",
      "metadata": {
        "id": "fd7fb04e-c457-4093-ba9e-da0b063b6427"
      },
      "source": [
        "We need to define some filtering operator. We will consider $F_\\tau = \\tau I - \\mathcal{H}$ for a constant $\\tau \\ge E_\\mathrm{max}$ since it's a very simple one that is indeed equivalent to a regular VQE. \n",
        "\n",
        "***\n",
        "\n",
        "Next, we would have to define our objective function, which is\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "\\mathcal{C}_{t}(\\boldsymbol{\\theta}) &=\\frac{1}{2} \\||\\psi(\\boldsymbol{\\theta})\\rangle-\\left|F_{t} \\psi_{t-1}\\right\\rangle \\|^{2} \\\\\n",
        "&=1-\\frac{\\operatorname{Re}\\left\\langle\\psi_{t-1}\\left|F_{t}\\right| \\psi(\\boldsymbol{\\theta})\\right\\rangle}{\\sqrt{\\left\\langle F_{t}^{2}\\right\\rangle_{\\psi_{t-1}}}}\n",
        "\\end{aligned}\n",
        "\\end{equation}\n",
        "\n",
        "However, given that the gradient descent update is written as\n",
        "\n",
        "\\begin{equation}\n",
        "\\boldsymbol{\\theta}_{t}=\\boldsymbol{\\theta}_{t-1}-\\left.\\eta \\sum_{j=1}^{m} \\frac{\\partial \\mathcal{C}_{t}(\\boldsymbol{\\theta})}{\\partial \\theta_{j}}\\right|_{\\boldsymbol{\\theta}_{t-1}} \\boldsymbol{e}_{j},\n",
        "\\end{equation}\n",
        "\n",
        "and we have an analytic expression for those derivatives\n",
        "\n",
        "\\begin{equation}\n",
        "\\left.\\frac{\\partial \\mathcal{C}_{t}(\\boldsymbol{\\theta})}{\\partial \\theta_{j}}\\right|_{\\boldsymbol{\\theta}_{t-1}}=-\\frac{\\left\\langle F_{t}\\right\\rangle_{\\psi_{t-1}^{j}}-\\left\\langle F_{t}\\right\\rangle_{\\psi_{t-1}^{j-}}}{4 \\sqrt{\\left\\langle F_{t}^{2}\\right\\rangle_{\\psi_{t-1}}}},\n",
        "\\end{equation}\n",
        "\n",
        "there is no need to evaluate that objective function $C_t(\\theta)$.\n",
        "\n",
        "***\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2e308a07-771b-498b-b00c-0dbe5d5c9335",
      "metadata": {
        "id": "2e308a07-771b-498b-b00c-0dbe5d5c9335"
      },
      "outputs": [],
      "source": [
        "def filtering_function6(E, c):\n",
        "    return (c-E)\n",
        "\n",
        "def bitstring_energy(H, bitstring):\n",
        "    \n",
        "    bitstring = bitstring[::-1]    \n",
        "    #print(bitstring)\n",
        "    spins = np.array([(-1)**(b == '1') for b in bitstring])\n",
        "    #print(spins)\n",
        "    value = 0\n",
        "          \n",
        "    for i, coef in enumerate(H.coeffs):\n",
        "        #print(\"i is\",i)\n",
        "        weight = np.real(coef)\n",
        "        indices = np.where(H.primitive.table.Z[i])\n",
        "        #print(\"indices are:\",indices[0])\n",
        "        #print(\"------------\")\n",
        "        value += weight * np.prod(spins[indices])\n",
        "    \n",
        "    return value\n",
        "\n",
        "\n",
        "def expectation(H,theta,n,l,shots,tau,filtering,power):\n",
        "    \n",
        "    circuit=Ansatz(theta,n,l)\n",
        "    circuit.measure_all()\n",
        "        \n",
        "    backend = Aer.get_backend('qasm_simulator')\n",
        "    job = execute(circuit, backend, shots=shots)\n",
        "    result = job.result()\n",
        "    counts = result.get_counts()\n",
        "\n",
        "    F_exp=0\n",
        "    for bit,prob in counts.items():\n",
        "        \n",
        "        if filtering ==True:\n",
        "            if power==True:\n",
        "                F_exp+=(prob*filtering_function6(bitstring_energy(H, bit), tau)**2)\n",
        "            else:\n",
        "                F_exp+=(prob*filtering_function6(bitstring_energy(H, bit), tau))\n",
        "        else:\n",
        "            F_exp+=(prob*energies[i])\n",
        "\n",
        "    return F_exp/shots\n",
        "\n",
        "def gradient(op, n,l, shots,tau):\n",
        "    def gradient_fn(params):\n",
        "        grad_list=[]\n",
        "        num_params = len(params)\n",
        "        \n",
        "        # Here, we apply the parameter shift-rule\n",
        "        param_sets_to_eval = params + np.concatenate(\n",
        "        (\n",
        "            np.eye(num_params) * np.pi / 2,  # copy of the parameters with the positive shift\n",
        "            -np.eye(num_params) * np.pi / 2,\n",
        "        ),  # copy of the parameters with the negative shift\n",
        "        axis=0,)\n",
        "        \n",
        "        denominator=4*np.sqrt(expectation(op,params,n,l,shots,tau,True,True))\n",
        "        for i in range(len(params)):\n",
        "            numerator=expectation(op,param_sets_to_eval[i],n,l,shots,tau,True,False)-expectation(op,param_sets_to_eval[i+len(params)],n,l,shots,tau,True,False)\n",
        "            grad_list.append(numerator/denominator)\n",
        "        return np.array(grad_list)\n",
        "    return gradient_fn\n",
        "\n",
        "def qiskit_expectation(op,n,l,shots):\n",
        "    def q_exp(theta):\n",
        "        psi = CircuitStateFn(Ansatz(theta,n,l))\n",
        "        # define your backend or quantum instance (where you can add settings)\n",
        "        backend = Aer.get_backend('qasm_simulator') \n",
        "        q_instance = QuantumInstance(backend, shots=shots)\n",
        "        # define the state to sample\n",
        "        measurable_expression = StateFn(op, is_measurement=True).compose(psi) \n",
        "        # convert to expectation value\n",
        "        expectation = PauliExpectation().convert(measurable_expression)  \n",
        "        # get state sampler (you can also pass the backend directly)\n",
        "        sampler = CircuitSampler(q_instance).convert(expectation) \n",
        "        ##print('Math:', psi.adjoint().compose(op).compose(psi).eval().real)\n",
        "        # evaluate\n",
        "        return sampler.eval().real\n",
        "    return q_exp"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "996a7c64-9b50-4697-96bc-449f66ad5de0",
      "metadata": {
        "id": "996a7c64-9b50-4697-96bc-449f66ad5de0"
      },
      "source": [
        "Callback function for cost values which later can be used for visualization purpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "362464ab-a4ae-4adc-b3d0-b44fb536fcc2",
      "metadata": {
        "id": "362464ab-a4ae-4adc-b3d0-b44fb536fcc2"
      },
      "outputs": [],
      "source": [
        "F = c * (I^H.num_qubits) - H\n",
        "fvqe_cost, fvqe_iter=[],[]\n",
        "def callback(nfevs, x_next, cost, stepsize):\n",
        "    fvqe_cost.append(cost)\n",
        "    fvqe_iter.append(nfevs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d14e6f8d-b233-4df1-9ecd-5436c059f903",
      "metadata": {
        "id": "d14e6f8d-b233-4df1-9ecd-5436c059f903"
      },
      "source": [
        "FVQE algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e20f2e56-7081-4fa0-86d2-7626e91b7700",
      "metadata": {
        "id": "e20f2e56-7081-4fa0-86d2-7626e91b7700"
      },
      "outputs": [],
      "source": [
        "shots=1024\n",
        "num_qubits = H.num_qubits\n",
        "num_para=2*(num_qubits-1) # The number of parameters in each Layer (except Layer 0).\n",
        "c=9\n",
        "layers=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f72b51cb-09e1-4523-a53b-db9b535d73fd",
      "metadata": {
        "id": "f72b51cb-09e1-4523-a53b-db9b535d73fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a167d4b3-653d-4a1d-94fb-b8748614df46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.47761661 1.52794645 0.66754937 1.51923313]\n",
            "-272409.287741662\n",
            "DONE\n",
            "-----------------------\n",
            "\n",
            "*REPORT*\n",
            "\n",
            "Quantum Cost is :  2737.781786348205\n",
            "Classical Cost is :  2737.781786348361\n"
          ]
        }
      ],
      "source": [
        "# Changes are made here in relation to errors that came up when implementing the original code\n",
        "ss = process_time()\n",
        "theta= np.asarray([*((np.pi/2)*np.ones(num_qubits)),*(np.zeros(2*(num_qubits-1)*layers))])\n",
        "optimizer = GradientDescent(maxiter=80,learning_rate=1.0, callback=callback)\n",
        "\n",
        "obj = qiskit_expectation(H,num_qubits,layers,shots) # <H>\n",
        "\n",
        "grad_fun = gradient(F, num_qubits,layers, shots,c)\n",
        "\n",
        "#result = optimizer.optimize(num_vars=num_qubits+2*(num_qubits-1)*layers, objective_function=obj,gradient_function=grad_fun, initial_point=theta)\n",
        "result = optimizer.minimize(fun=obj, x0=theta,jac=grad_fun) # Revised version of the above lime with the same effect.\n",
        "print(result.x) # Optimal parameters; creates a list of outputs\n",
        "print(result.fun) # minimum parameter; result in a single output\n",
        "print(\"DONE\")\n",
        "print(\"-----------------------\")\n",
        "print(\"\\n*REPORT*\\n\")\n",
        "qc = Ansatz(result.x, num_qubits, layers)\n",
        "qc.measure_all()\n",
        "\n",
        "# New code not related to the errors from the original code.\n",
        "backend = AerSimulator()\n",
        "# Setting an executor and a maximum job size (maximum number of circuits that can make up a job)\n",
        "excute = ThreadPoolExecutor(max_workers=2)\n",
        "backend.set_options(executor=excute)\n",
        "backend.set_options(max_job_size=1) \n",
        "# result = backend.run(circ_list).result()\n",
        "# End of new code\n",
        "\n",
        "# backend = Aer.get_backend('qasm_simulator'); Removed because of the above groups of code.\n",
        "job = execute(qc, backend, shots=shots)\n",
        "res = job.result()\n",
        "counts = res.get_counts()\n",
        "revsol = counts.most_frequent()[::-1]\n",
        "sol = np.array(list(revsol), dtype=int)\n",
        "_,_,_,level = quantum_optimizer.binary_representation(x_sol=sol)\n",
        "print(\"Quantum Cost is : \",level)\n",
        "print(\"Classical Cost is : \",classical_cost)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Qiskit v0.32.0 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "Reduced Runtime Version of FVQE_VRP.ipynb - SiddharthC",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}